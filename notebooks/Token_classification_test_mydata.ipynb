{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iHLGJRxNJQh5"
   },
   "source": [
    "# Token classification (PyTorch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moralization import spacy_model\n",
    "import torch\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datasets\n",
    "import evaluate\n",
    "from accelerate import Accelerator\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "from transformers import DataCollatorForTokenClassification\n",
    "from transformers import get_scheduler\n",
    "torch.cuda.is_available()\n",
    "# import data as spacy doc and take it from there\n",
    "data_dir = \"../data/All_Data/XMI_11\"\n",
    "test_setup = spacy_model.SpacySetup(data_dir, working_dir=\"./test\")\n",
    "data_doc = test_setup.doc_dict\n",
    "example_name = list(data_doc.keys())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_list = [[token.text for token in sent] for sent in data_doc[example_name][\"train\"].sents]\n",
    "token_list = [[token for token in sent] for sent in data_doc[example_name][\"train\"].sents]\n",
    "# initialize nested label list to 0\n",
    "label_list = [[0 for token in sent] for sent in data_doc[example_name][\"train\"].sents]\n",
    "for i in range(0, 5):\n",
    "    print(sentence_list[i])\n",
    "    print(label_list[i])\n",
    "# generate the labels based on the current list of tokens\n",
    "# now set all Moralisierung, Moralisierung Kontext,\n",
    "# Moralisierung explizit, Moralisierung interpretativ, Moralisierung Weltwissen to 1\n",
    "selected_labels = [\"Moralisierung\", \"Moralisierung Kontext\", \"Moralisierung Weltwissen\",\n",
    "                   \"Moralisierung explizit\", \"Moralisierung interpretativ\"]\n",
    "# create a list as long as tokens\n",
    "labels = [0 for token in data_doc[example_name][\"train\"]]\n",
    "for span in data_doc[example_name][\"train\"].spans[\"task1\"]:\n",
    "    if span.label_ in selected_labels:\n",
    "        labels[span.start+1:span.end] = [1] * (span.end-span.start)\n",
    "        # mark the beginning of a span with 2\n",
    "        labels[span.start] = 2\n",
    "\n",
    "# labels now needs to be structured the same way as label_list\n",
    "# set the label at beginning of sentence to 2 if it is 1\n",
    "# also punctuation is included in the moralization label - we\n",
    "# definitely need to set those labels to -100\n",
    "j = 0\n",
    "for m in range(len(label_list)):\n",
    "    for i in range(len(label_list[m])):\n",
    "        label_list[m][i] = labels[j]\n",
    "        if i == 0 and labels[j] == 1:\n",
    "            label_list[m][i] = 2\n",
    "        if token_list[m][i].is_punct:\n",
    "            label_list[m][i] = -100\n",
    "        j = j+1\n",
    "\n",
    "\n",
    "for i in range(0, 10):\n",
    "    print(sentence_list[i])\n",
    "    print(label_list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# at this point we can write the text into a csv to load into datasets\n",
    "# later it can be published as such on huggingface datasets\n",
    "# column heads are sentence, labels\n",
    "df = pd.DataFrame(zip(sentence_list, label_list), columns=[\"Sentences\", \"Labels\"])\n",
    "print(df.head(10))\n",
    "data_set = datasets.Dataset.from_pandas(df)\n",
    "# split in train test\n",
    "train_test_set = data_set.train_test_split(test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_set[\"train\"][0:100][\"Labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"bert-base-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "tokenizer.is_fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(train_test_set[\"train\"][9][\"Sentences\"], is_split_into_words=True)\n",
    "inputs.tokens()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label_list needs to be expanded to cover the new tokens\n",
    "# beginning of a span needs a different label than inside of a span\n",
    "def align_labels_with_tokens(labels, word_ids):\n",
    "    new_labels = []\n",
    "    current_word = None\n",
    "    for word_id in word_ids:\n",
    "        if word_id != current_word:\n",
    "            # Start of a new word!\n",
    "            current_word = word_id\n",
    "            label = -100 if word_id is None else labels[word_id]\n",
    "            new_labels.append(label)\n",
    "        elif word_id is None:\n",
    "            # Special token\n",
    "            new_labels.append(-100)\n",
    "        else:\n",
    "            # Same word as previous token\n",
    "            label = labels[word_id]\n",
    "            # If the label is B-XXX we change it to I-XXX\n",
    "            if label == 2:\n",
    "                label -= 1\n",
    "            new_labels.append(label)\n",
    "    return new_labels\n",
    "\n",
    "\n",
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(\n",
    "        examples[\"Sentences\"], truncation=True, is_split_into_words=True\n",
    "    )\n",
    "    all_labels = examples[\"Labels\"]\n",
    "    new_labels = []\n",
    "    tokens = []\n",
    "    for i, labels in enumerate(all_labels):\n",
    "        word_ids = tokenized_inputs.word_ids(i)\n",
    "        tokens.append(tokenized_inputs.tokens(i))\n",
    "        new_labels.append(align_labels_with_tokens(labels, word_ids))\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = new_labels\n",
    "#     tokenized_inputs[\"tokens\"] = tokens\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets = train_test_set.map(\n",
    "    tokenize_and_align_labels,\n",
    "    batched=True,\n",
    "    remove_columns=train_test_set[\"train\"].column_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-bP71JFwJQiF"
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HW-b5rEPJQiF",
    "outputId": "9b423627-f808-4a4f-b34c-1995b2570df6"
   },
   "outputs": [],
   "source": [
    "batch = data_collator([tokenized_datasets[\"train\"][i] for i in range(2)])\n",
    "batch[\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zBqRd3DVJQiF",
    "outputId": "edcc88d8-ac03-4cba-9618-54c274fabb33"
   },
   "outputs": [],
   "source": [
    "for i in range(20):\n",
    "    print(tokenized_datasets[\"train\"][i][\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6lVyJf-oJQiG"
   },
   "outputs": [],
   "source": [
    "metric = evaluate.load(\"seqeval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r4j6oYEEJQiG",
    "outputId": "f1d0b881-2a9e-467e-ee77-6e111d81dcd8"
   },
   "outputs": [],
   "source": [
    "# labels = raw_datasets[\"train\"][0][\"ner_tags\"]\n",
    "# labels = [label_names[i] for i in labels]\n",
    "label_names = [\"0\", \"M\", \"M-BEG\"]\n",
    "labels = train_test_set[\"train\"][0][\"Labels\"]\n",
    "labels = [label_names[i] for i in labels if i != -100]\n",
    "labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KmM5hjfQJQiG",
    "outputId": "c65b86e2-647c-41f5-c748-4c9cb197b354"
   },
   "outputs": [],
   "source": [
    "predictions = labels.copy()\n",
    "predictions[2] = \"O\"\n",
    "metric.compute(predictions=[predictions], references=[labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6JE8RwzxJQiG"
   },
   "outputs": [],
   "source": [
    "def compute_metrics(eval_preds):\n",
    "    logits, labels = eval_preds\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "\n",
    "    # Remove ignored index (special tokens) and convert to labels\n",
    "    true_labels = [[label_names[m] for m in label if m != -100] for label in labels]\n",
    "    true_predictions = [\n",
    "        [label_names[p] for (p, m) in zip(prediction, label) if m != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    all_metrics = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "    return {\n",
    "        \"precision\": all_metrics[\"overall_precision\"],\n",
    "        \"recall\": all_metrics[\"overall_recall\"],\n",
    "        \"f1\": all_metrics[\"overall_f1\"],\n",
    "        \"accuracy\": all_metrics[\"overall_accuracy\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jYcU4mMcJQiG"
   },
   "outputs": [],
   "source": [
    "id2label = {i: label for i, label in enumerate(label_names)}\n",
    "label2id = {v: k for k, v in id2label.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "om5rAJZTJQiG"
   },
   "outputs": [],
   "source": [
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    model_checkpoint,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PowPjfvEJQiH",
    "outputId": "ffb01359-68b9-4582-a4e3-a0ece49510a5"
   },
   "outputs": [],
   "source": [
    "model.config.num_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RsEAYgiSJQiH"
   },
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(\n",
    "    tokenized_datasets[\"train\"],\n",
    "    shuffle=True,\n",
    "    collate_fn=data_collator,\n",
    "    batch_size=8,\n",
    ")\n",
    "eval_dataloader = DataLoader(\n",
    "    tokenized_datasets[\"test\"],\n",
    "    collate_fn=data_collator,\n",
    "    batch_size=8,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c8V8EN5oJQiI"
   },
   "outputs": [],
   "source": [
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    model_checkpoint,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bae3vQoIJQiI"
   },
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d_ujG8ukJQiI"
   },
   "outputs": [],
   "source": [
    "accelerator = Accelerator()\n",
    "model, optimizer, train_dataloader, eval_dataloader = accelerator.prepare(\n",
    "    model, optimizer, train_dataloader, eval_dataloader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mvLRZdpyJQiI"
   },
   "outputs": [],
   "source": [
    "num_train_epochs = 3\n",
    "num_update_steps_per_epoch = len(train_dataloader)\n",
    "num_training_steps = num_train_epochs * num_update_steps_per_epoch\n",
    "\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=num_training_steps,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \".\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6Ftz7qfAJQiI"
   },
   "outputs": [],
   "source": [
    "def postprocess(predictions, labels):\n",
    "    predictions = predictions.detach().cpu().clone().numpy()\n",
    "    labels = labels.detach().cpu().clone().numpy()\n",
    "\n",
    "    # Remove ignored index (special tokens) and convert to labels\n",
    "    true_labels = [[label_names[m] for m in label if m != -100] for label in labels]\n",
    "    true_predictions = [\n",
    "        [label_names[p] for (p, m) in zip(prediction, label) if m != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    return true_labels, true_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wo1GW-txJQiI"
   },
   "outputs": [],
   "source": [
    "progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "for epoch in range(num_train_epochs):\n",
    "    # Training\n",
    "    model.train()\n",
    "    for batch in train_dataloader:\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        accelerator.backward(loss)\n",
    "\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        progress_bar.update(1)\n",
    "\n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    for batch in eval_dataloader:\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**batch)\n",
    "\n",
    "        predictions = outputs.logits.argmax(dim=-1)\n",
    "        labels = batch[\"labels\"]\n",
    "\n",
    "        # Necessary to pad predictions and labels for being gathered\n",
    "        predictions = accelerator.pad_across_processes(predictions, dim=1, pad_index=-100)\n",
    "        labels = accelerator.pad_across_processes(labels, dim=1, pad_index=-100)\n",
    "\n",
    "        predictions_gathered = accelerator.gather(predictions)\n",
    "        labels_gathered = accelerator.gather(labels)\n",
    "\n",
    "        true_predictions, true_labels = postprocess(predictions_gathered, labels_gathered)\n",
    "        metric.add_batch(predictions=true_predictions, references=true_labels)\n",
    "\n",
    "    results = metric.compute()\n",
    "    print(\n",
    "        f\"epoch {epoch}:\",\n",
    "        {\n",
    "            key: results[f\"overall_{key}\"]\n",
    "            for key in [\"precision\", \"recall\", \"f1\", \"accuracy\"]\n",
    "        },\n",
    "    )\n",
    "\n",
    "    # Save and upload\n",
    "    accelerator.wait_for_everyone()\n",
    "    unwrapped_model = accelerator.unwrap_model(model)\n",
    "    unwrapped_model.save_pretrained(output_dir, save_function=accelerator.save)\n",
    "    if accelerator.is_main_process:\n",
    "        tokenizer.save_pretrained(output_dir)\n",
    "#         repo.push_to_hub(\n",
    "#             commit_message=f\"Training in progress epoch {epoch}\", blocking=False\n",
    "#         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K9uHoOVRJQiJ"
   },
   "outputs": [],
   "source": [
    "accelerator.wait_for_everyone()\n",
    "unwrapped_model = accelerator.unwrap_model(model)\n",
    "unwrapped_model.save_pretrained(output_dir, save_function=accelerator.save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fUSoecaOJQiJ",
    "outputId": "f6614137-da44-4a92-d2df-f65577c5b92b"
   },
   "outputs": [],
   "source": [
    "# flake8-noqa-cell\n",
    "from transformers import pipeline\n",
    "\n",
    "# Replace this with your own checkpoint\n",
    "model_checkpoint = \".\"\n",
    "token_classifier = pipeline(\n",
    "    \"token-classification\", model=model_checkpoint, aggregation_strategy=\"simple\"\n",
    ")\n",
    "token_classifier(\"Das Arbeitslosengeld ist nicht hoch genug da man ungleiche Standards propagiert.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Token classification (PyTorch)",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
